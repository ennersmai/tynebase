/**
 * Test Vertex AI using API key with direct HTTP calls
 * Based on the Vertex AI API quickstart
 */

import * as dotenv from 'dotenv';

dotenv.config();

async function test() {
  console.log('üîç Testing Vertex AI with API Key (Direct HTTP)...\n');
  
  const apiKey = process.env.GOOGLE_API_KEY;
  
  if (!apiKey) {
    console.log('‚ùå GOOGLE_API_KEY not found in .env');
    return;
  }
  
  console.log(`API Key: ${apiKey.substring(0, 15)}...\n`);
  
  const modelsToTry = [
    'gemini-2.5-flash-lite',
    'gemini-2.0-flash-exp',
    'gemini-1.5-flash',
    'gemini-1.5-pro',
  ];
  
  for (const modelName of modelsToTry) {
    try {
      process.stdout.write(`Trying ${modelName}... `);
      
      const url = `https://aiplatform.googleapis.com/v1/publishers/google/models/${modelName}:streamGenerateContent?key=${apiKey}`;
      
      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            role: 'user',
            parts: [{
              text: 'Say "Hello from Gemini!" and confirm you are working correctly.'
            }]
          }]
        })
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        if (response.status === 404) {
          console.log('‚ùå Not found');
        } else if (response.status === 403) {
          console.log('‚ùå Permission denied');
        } else if (response.status === 401) {
          console.log('‚ùå Unauthorized');
        } else {
          console.log(`‚ùå Error ${response.status}`);
        }
        continue;
      }
      
      // Read streaming response
      const text = await response.text();
      
      // Parse the streaming response - it's a JSON array wrapped in []
      let fullText = '';
      let usageMetadata = null;
      
      try {
        // Parse as JSON array
        const data = JSON.parse(text);
        
        if (Array.isArray(data)) {
          // Iterate through streaming chunks
          for (const chunk of data) {
            const content = chunk.candidates?.[0]?.content?.parts?.[0]?.text;
            if (content) fullText += content;
            if (chunk.usageMetadata) usageMetadata = chunk.usageMetadata;
          }
        } else {
          // Single response object
          const content = data.candidates?.[0]?.content?.parts?.[0]?.text;
          if (content) fullText = content;
          if (data.usageMetadata) usageMetadata = data.usageMetadata;
        }
      } catch (e: any) {
        console.log('‚ùå Failed to parse response:', e.message);
      }
      
      console.log('‚úÖ WORKS!\n');
      console.log('‚úÖ ‚úÖ ‚úÖ SUCCESS! ‚úÖ ‚úÖ ‚úÖ\n');
      console.log(`Working model: ${modelName}`);
      console.log('API: Vertex AI (aiplatform.googleapis.com)\n');
      console.log('Response:');
      console.log('‚îÄ'.repeat(60));
      console.log(fullText || 'No response text');
      console.log('‚îÄ'.repeat(60));
      
      if (usageMetadata) {
        console.log('\nüìä Token Usage:');
        console.log(`   Input: ${usageMetadata.promptTokenCount || 0}`);
        console.log(`   Output: ${usageMetadata.candidatesTokenCount || 0}`);
        console.log(`   Total: ${usageMetadata.totalTokenCount || 0}`);
      }
      console.log('');
      return;
      
    } catch (error: any) {
      console.log(`‚ùå ${error.message}`);
    }
  }
  
  console.log('\n‚ùå No working models found.');
}

test();
